{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the Function used for attack (C&W). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CW Attack\n",
    "from torch import nn\n",
    "import torch\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "def cw_l2_attack(model, images, labels, targeted=False, c=1e-4, kappa=0, max_iter=1000, learning_rate=0.01) :\n",
    "    images = images.to(device)     \n",
    "    labels = labels.to(device)\n",
    "    # Define f-function\n",
    "    def f(x) :\n",
    "        outputs = model(x)\n",
    "        one_hot_labels = torch.eye(len(outputs[0]))[labels].to(device)\n",
    "        i, _ = torch.max((1-one_hot_labels)*outputs, dim=1)\n",
    "        j = torch.masked_select(outputs, one_hot_labels.byte())       \n",
    "        # If targeted, optimize for making the other class most likely \n",
    "        if targeted :\n",
    "            return torch.clamp(i-j, min=-kappa)       \n",
    "        # If untargeted, optimize for making the other class most likely \n",
    "        else :\n",
    "            return torch.clamp(j-i, min=-kappa)\n",
    "    w = torch.zeros_like(images, requires_grad=True).to(device)\n",
    "    optimizer = torch.optim.Adam([w], lr=learning_rate)\n",
    "    prev = 1e10\n",
    "    for step in range(max_iter) :\n",
    "        a = 1/2*(nn.Tanh()(w) + 1)\n",
    "        loss1 = nn.MSELoss(reduction='sum')(a, images)\n",
    "        loss2 = torch.sum(c*f(a))\n",
    "        cost = loss1 + loss2\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        # Early Stop when loss does not converge.\n",
    "        if step % (max_iter//10) == 0 :\n",
    "            if cost > prev :\n",
    "                print('Attack Stopped due to CONVERGENCE....')\n",
    "                return a\n",
    "            prev = cost\n",
    "        #print(f'Learning Progress : {(step+1)/max_iter*100}')\n",
    "    attack_images = 1/2*(nn.Tanh()(w) + 1)\n",
    "    return attack_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is how it should be used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Attack Image & Predicted Label\")\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in testloader:\n",
    "    images = cw_l2_attack(model, images, labels, targeted=False, c=0.1)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, pre = torch.max(outputs.data, 1)\n",
    "    total += batch_size\n",
    "    correct += (pre == labels).sum()\n",
    "    #plt.imshow(torchvision.utils.make_grid(images.cpu().data, normalize=True), [normal_data.classes[i] for i in pre])\n",
    "print('Accuracy of test set: %f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PGD Attack based on FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGD Attack\n",
    "def pgd_attack(model, images, labels, alpha = 8/255, eps = 0.1, minimum = 0, maximum = 1, iterations = 100) :\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    original_images = images.data\n",
    "        \n",
    "    for i in range(iterations) :    \n",
    "        images.requires_grad = True\n",
    "        outputs = model(images)\n",
    "        model.zero_grad()\n",
    "        cost = loss(outputs, labels).to(device)\n",
    "        cost.backward()\n",
    "        adv_images = images + alpha*images.grad.sign()\n",
    "        eta = torch.clamp(adv_images - original_images, min=-eps, max=eps)\n",
    "        images = torch.clamp(original_images + eta, min=minimum, max=maximum).detach_()\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "#You can put train_loader as well\n",
    "for images, labels in test_loader:\n",
    "    alpha     = 8/255  #learning rate step in the direction of the attack\n",
    "    epsilon   = 0.1    #Upper_Bound on the infinity norm of the perturbation. \\|\\delta\\|_{infty} < epsilon \n",
    "    minimum   = 0      #Lower bound of the input value, i.e. 0 in the case if we want the image between [0,1]\n",
    "    maximum   = 1      #Upper bound of the input value, i.e  1 in the case if we want the image between [0,1]\n",
    "    iteration = 100    #Number of iterations performed to achieve the attack\n",
    "    \n",
    "    images = pgd_attack(model, images, labels)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    \n",
    "    _, pre = torch.max(outputs.data, 1)\n",
    "\n",
    "    total += batch_size\n",
    "    correct += (pre == labels).sum()\n",
    "        \n",
    "print(f'Accuracy of test text: {(100 * float(correct) / total)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:modar]",
   "language": "python",
   "name": "conda-env-modar-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
